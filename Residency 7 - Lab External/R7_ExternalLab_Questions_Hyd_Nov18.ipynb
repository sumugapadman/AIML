{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_ExternalLab_Questions_Hyd_Nov18.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6r_uerx_kDS",
        "colab_type": "text"
      },
      "source": [
        "## Build a DNN using Keras with RELU and ADAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjV30dJg_v1j",
        "colab_type": "text"
      },
      "source": [
        "**Load tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEi6Q4Pe_s_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip-7yt2u_5WL",
        "colab_type": "text"
      },
      "source": [
        "**Collect Fashion mnist data from tf.keras.datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QauDsea_1D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5f892bd5-f7e8-415a-afd3-0e97cc154862"
      },
      "source": [
        "(trainX, trainY),(testX, testY) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xi-dFWKAC8M",
        "colab_type": "text"
      },
      "source": [
        "**Change train and test labels into one-hot vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UFBwWmh_9lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpoNvzV3ALwA",
        "colab_type": "text"
      },
      "source": [
        "## Build the Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIuOpdO1AOYn",
        "colab_type": "text"
      },
      "source": [
        "**Initialize model, reshape & normalize data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynA_wGrDAHAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize model, reshape & normalize data\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdWdxCqEAaP_",
        "colab_type": "text"
      },
      "source": [
        "**Add two fully connected layers with 200 and 100 neurons respectively with relu activations. Add a dropout layer with p=0.25**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9MzgcnOAU00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "fae4379e-9692-4746-ce56-6a1452f8af95"
      },
      "source": [
        "#Hidden layers\n",
        "model.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
        "\n",
        "#Dropout layer\n",
        "model.add(tf.keras.layers.Dropout(0.25))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0619 09:12:12.375291 139881730717568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvFeKDYSAu8D",
        "colab_type": "text"
      },
      "source": [
        "**Add the output layer with a fully connected layer with 10 neurons with softmax activation. Use categorical_crossentropy loss and adam optimizer and train the network. And, report the final validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDo7rSvsAgYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W--QVPIA19d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1058
        },
        "outputId": "a86fe0d8-a854-4fc7-f11a-60328d9c14c9"
      },
      "source": [
        "#Train the model\n",
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          epochs=30,\n",
        "          batch_size=32)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.2617 - acc: 0.9200 - val_loss: 0.3592 - val_acc: 0.9505\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.1351 - acc: 0.9589 - val_loss: 0.3123 - val_acc: 0.9654\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.1014 - acc: 0.9691 - val_loss: 0.3636 - val_acc: 0.9714\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0826 - acc: 0.9751 - val_loss: 0.2447 - val_acc: 0.9715\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0714 - acc: 0.9771 - val_loss: 0.3172 - val_acc: 0.9719\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0619 - acc: 0.9802 - val_loss: 0.4007 - val_acc: 0.9705\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0546 - acc: 0.9826 - val_loss: 0.3163 - val_acc: 0.9730\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0509 - acc: 0.9840 - val_loss: 0.2286 - val_acc: 0.9708\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0446 - acc: 0.9858 - val_loss: 0.3115 - val_acc: 0.9691\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0418 - acc: 0.9862 - val_loss: 0.3287 - val_acc: 0.9731\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0389 - acc: 0.9880 - val_loss: 0.6512 - val_acc: 0.9709\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0398 - acc: 0.9871 - val_loss: 0.2847 - val_acc: 0.9755\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0347 - acc: 0.9890 - val_loss: 0.3939 - val_acc: 0.9737\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0355 - acc: 0.9891 - val_loss: 0.4471 - val_acc: 0.9718\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0309 - acc: 0.9898 - val_loss: 0.6438 - val_acc: 0.9754\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0351 - acc: 0.9894 - val_loss: 0.3872 - val_acc: 0.9726\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0315 - acc: 0.9898 - val_loss: 0.4882 - val_acc: 0.9729\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0311 - acc: 0.9907 - val_loss: 0.4056 - val_acc: 0.9744\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0278 - acc: 0.9918 - val_loss: 0.3925 - val_acc: 0.9719\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0290 - acc: 0.9919 - val_loss: 0.3687 - val_acc: 0.9736\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.0261 - acc: 0.9918 - val_loss: 0.5089 - val_acc: 0.9732\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0268 - acc: 0.9922 - val_loss: 0.5719 - val_acc: 0.9738\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0246 - acc: 0.9927 - val_loss: 0.4890 - val_acc: 0.9735\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0246 - acc: 0.9928 - val_loss: 0.4357 - val_acc: 0.9726\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0255 - acc: 0.9927 - val_loss: 0.3786 - val_acc: 0.9702\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0270 - acc: 0.9926 - val_loss: 0.5515 - val_acc: 0.9716\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0217 - acc: 0.9935 - val_loss: 0.5128 - val_acc: 0.9713\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0231 - acc: 0.9926 - val_loss: 0.6819 - val_acc: 0.9724\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0224 - acc: 0.9932 - val_loss: 0.6980 - val_acc: 0.9728\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0244 - acc: 0.9938 - val_loss: 0.4274 - val_acc: 0.9715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3888276048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQT_3RhABAFo",
        "colab_type": "text"
      },
      "source": [
        "## DATA AUGMENTATION ON CIFAR10 DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3XG4kD8BDMg",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkfOXo0MBIeA",
        "colab_type": "text"
      },
      "source": [
        "**Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-bsrFEuBMpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0e26aad-99e3-4370-e540-7e4e04dcc655"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewm6rLvKBP8m",
        "colab_type": "text"
      },
      "source": [
        "**Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9vYMSLyBSNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "870ca91d-7af4-4193-b2f6-0f4d656ab2db"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJTXVB2UBXmc",
        "colab_type": "text"
      },
      "source": [
        "**Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LwpAp7BBcQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJh_4jmEBctY",
        "colab_type": "text"
      },
      "source": [
        "**Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppJzKpYwBhlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7fi2cYBBiJa",
        "colab_type": "text"
      },
      "source": [
        "**Generate 5 images for 1 of the image of CIFAR10 train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qUjU6nHBnSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "8b5e9c09-9098-4058-e871-6e0a798acae5"
      },
      "source": [
        "gen = data_gen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 09:22:26.850308 139881730717568 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "W0619 09:22:26.867439 139881730717568 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "W0619 09:22:26.885173 139881730717568 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "W0619 09:22:26.901307 139881730717568 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "W0619 09:22:26.916790 139881730717568 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABcCAYAAAB3AO7GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAX5JREFUeJzt2zEOhDAMAEGC7v9fNg+A5ihAK2bq\nSLFcrNJkzcwGQM/+9gAA3CPgAFECDhAl4ABRAg4QJeAAUQIOECXgAFECDhD1e/i+r3z7XH+ctZMz\nO7lmL2ef3okXOECUgANECThAlIADRAk4QJSAA0QJOECUgANECThAlIADRAk4QJSAA0QJOECUgANE\nCThAlIADRAk4QJSAA0QJOECUgANECThAlIADRAk4QJSAA0QJOECUgANECThAlIADRAk4QJSAA0QJ\nOECUgANECThAlIADRAk4QJSAA0QJOECUgANECThAlIADRAk4QJSAA0QJOECUgANECThAlIADRAk4\nQJSAA0QJOECUgANECThAlIADRAk4QJSAA0QJOECUgANECThA1JqZt2cA4AYvcIAoAQeIEnCAKAEH\niBJwgCgBB4gScIAoAQeIEnCAKAEHiBJwgCgBB4gScIAoAQeIEnCAKAEHiBJwgCgBB4gScIAoAQeI\nEnCAKAEHiBJwgKgDEPcLs4ZWiSUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeW6zBEJCtSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}