{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI9UoigGyBXz",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset\n",
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGDmq0WoyKav",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8VzB8zNyLPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e964ac42-dcd7-486c-c438-7b653ac4aa47"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import vis\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ThQHZ0yY2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "d151d09a-ef4a-49a3-f0da-4b7b2275bdcb"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 4s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D0enCdoy47l",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxU2eyH_y6Ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04930c8a-2cb1-422c-f80d-89dfb81f2fbe"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbboV26FzKR2",
        "colab_type": "text"
      },
      "source": [
        "##Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlFuOpXnzOHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae9842ca-5eac-4f46-e608-d76cd64032b8"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGlhSBb1zyy4",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "**check `keras.utils.to_categorical()`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUjU6T53zz3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_conv = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test_conv = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzc4IaBg0IoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_class = keras.utils.to_categorical(y_train, 10)\n",
        "y_test_class = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwm0hVi30aa1",
        "colab_type": "text"
      },
      "source": [
        "##Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sINeELL10T2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_conv =  x_train_conv.astype(\"float32\") / 255\n",
        "x_test_conv = x_test_conv.astype(\"float32\") / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFGieIo_00zE",
        "colab_type": "text"
      },
      "source": [
        "##Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epjgfWBp0tv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_conv = x_train.reshape(x_train_conv.shape[0], 28, 28, 1)\n",
        "x_test_conv = x_test.reshape(x_test_conv.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vt3C-Cp1HgJ",
        "colab_type": "text"
      },
      "source": [
        "##Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpLVjgJq1mdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UdQ4Epa1Omb",
        "colab_type": "text"
      },
      "source": [
        "##Build a model \n",
        "\n",
        "**with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrueviC-1vXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a9b0316c-66f4-45f5-b8c7-ed351bae56d8"
      },
      "source": [
        "model_simple_conv = Sequential()\n",
        "model_simple_conv.add(Conv2D(32, (3, 3), activation =\"relu\", input_shape=(28, 28, 1)))\n",
        "model_simple_conv.add(Conv2D(32, (3, 3), activation =\"relu\"))\n",
        "model_simple_conv.add(Flatten())\n",
        "model_simple_conv.add(Dense(128, activation='relu'))\n",
        "model_simple_conv.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTxaOdEi123B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ad3ac278-291a-49db-9acb-5371c9b3f99e"
      },
      "source": [
        "model_simple_conv.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               2359424   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,370,282\n",
            "Trainable params: 2,370,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rutoc5617D_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_simple_conv.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzjjgYZg2ACe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "dc82b9c5-24ed-4de9-affd-2df46613d053"
      },
      "source": [
        "%%time \n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = [EarlyStopping(patience=5)]\n",
        "output_pooling_conv = model_simple_conv.fit(x_train_conv, y_train_class, batch_size=512, epochs=10, verbose=2, callbacks=early_stopping,\n",
        "                    validation_data=(x_test_conv, y_test_class))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 130s - loss: 12.9261 - acc: 0.1970 - val_loss: 12.9138 - val_acc: 0.1988\n",
            "Epoch 2/10\n",
            " - 128s - loss: 12.9578 - acc: 0.1960 - val_loss: 12.9025 - val_acc: 0.1995\n",
            "Epoch 3/10\n",
            " - 126s - loss: 12.9009 - acc: 0.1996 - val_loss: 12.9025 - val_acc: 0.1995\n",
            "Epoch 4/10\n",
            " - 125s - loss: 12.9009 - acc: 0.1996 - val_loss: 12.9025 - val_acc: 0.1995\n",
            "Epoch 5/10\n",
            " - 125s - loss: 12.9009 - acc: 0.1996 - val_loss: 12.9025 - val_acc: 0.1995\n",
            "Epoch 6/10\n",
            " - 125s - loss: 12.9009 - acc: 0.1996 - val_loss: 12.9025 - val_acc: 0.1995\n",
            "Epoch 7/10\n",
            " - 125s - loss: 12.9009 - acc: 0.1996 - val_loss: 12.9025 - val_acc: 0.1995\n",
            "CPU times: user 28min 35s, sys: 25.1 s, total: 29min\n",
            "Wall time: 14min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8dSwIS_1aVy",
        "colab_type": "text"
      },
      "source": [
        "##Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mJOkxwS6aOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "28014fd6-622e-4335-98ab-2da06be12917"
      },
      "source": [
        "model_pooling_conv = Sequential()\n",
        "model_pooling_conv.add(Conv2D(32, (3, 3), activation =\"relu\", input_shape=(28, 28, 1)))\n",
        "model_pooling_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_pooling_conv.add(Dropout(0.25))\n",
        "model_pooling_conv.add(Conv2D(32, (3, 3), activation =\"relu\"))\n",
        "model_pooling_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_pooling_conv.add(Dropout(0.25))\n",
        "model_pooling_conv.add(Flatten())\n",
        "model_pooling_conv.add(Dense(128, activation='relu'))\n",
        "model_pooling_conv.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEp5lx6a60qT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "3da101ea-3cdc-4a7b-cee4-74f2348bf809"
      },
      "source": [
        "model_pooling_conv.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM89mMC566tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_pooling_conv.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYiJb3I06_rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "a5ccb037-1c25-447f-f904-266064184b65"
      },
      "source": [
        "%%time \n",
        "from keras.callbacks import EarlyStopping\n",
        "output_pooling_conv = model_pooling_conv.fit(x_train_conv, y_train_class, batch_size=512, epochs=10, verbose=2, callbacks=early_stopping,\n",
        "                    validation_data=(x_test_conv, y_test_class))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 54s - loss: 3.8951 - acc: 0.5793 - val_loss: 0.6963 - val_acc: 0.7563\n",
            "Epoch 2/10\n",
            " - 53s - loss: 0.6310 - acc: 0.7711 - val_loss: 0.5048 - val_acc: 0.8204\n",
            "Epoch 3/10\n",
            " - 53s - loss: 0.5132 - acc: 0.8119 - val_loss: 0.4452 - val_acc: 0.8398\n",
            "Epoch 4/10\n",
            " - 53s - loss: 0.4575 - acc: 0.8325 - val_loss: 0.4038 - val_acc: 0.8541\n",
            "Epoch 5/10\n",
            " - 53s - loss: 0.4172 - acc: 0.8456 - val_loss: 0.3848 - val_acc: 0.8592\n",
            "Epoch 6/10\n",
            " - 53s - loss: 0.3930 - acc: 0.8540 - val_loss: 0.3793 - val_acc: 0.8564\n",
            "Epoch 7/10\n",
            " - 53s - loss: 0.3732 - acc: 0.8615 - val_loss: 0.3448 - val_acc: 0.8712\n",
            "Epoch 8/10\n",
            " - 53s - loss: 0.3540 - acc: 0.8685 - val_loss: 0.3269 - val_acc: 0.8817\n",
            "Epoch 9/10\n",
            " - 52s - loss: 0.3388 - acc: 0.8741 - val_loss: 0.3222 - val_acc: 0.8824\n",
            "Epoch 10/10\n",
            " - 52s - loss: 0.3297 - acc: 0.8763 - val_loss: 0.3186 - val_acc: 0.8832\n",
            "CPU times: user 16min 45s, sys: 19.6 s, total: 17min 5s\n",
            "Wall time: 8min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f93crkDN1hIw",
        "colab_type": "text"
      },
      "source": [
        "##Now, to the above model, lets add Data Augmentation\n",
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Yn5-BN08Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntq28hqW9XBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rLuIu6W9bhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(x_train_conv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8GBwHg49kT-",
        "colab_type": "text"
      },
      "source": [
        "##Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s21pKXgO9fbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "d13ca99d-3ef3-4a46-9616-6a2f3ee6316f"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train_conv[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT0CAuAb9_41",
        "colab_type": "text"
      },
      "source": [
        "##Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgOfHhrE9pAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4019ef6-d1f5-41f2-a7ca-f47a048f76f4"
      },
      "source": [
        "x_train_conv[:1].shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucQQas6Y-FG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen.fit(x_train_conv[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvRdTtek-HF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = datagen.flow(x_train_conv[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ILK-W_K-JWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = []\n",
        "for i in range(3):\n",
        "    img = samples.next()\n",
        "    img = img.squeeze()\n",
        "    image.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkoZRizK-MPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3326
        },
        "outputId": "81c6f574-3403-444b-8177-f843bd01992f"
      },
      "source": [
        "image[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        5.39442003e-01, 8.04654479e-01, 2.01838002e-01, 7.89697945e-01],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.50176227e-01, 1.41780972e+00,\n",
              "        4.67759788e-01, 0.00000000e+00, 2.27447778e-01, 1.19306183e+00,\n",
              "        9.59933162e-01, 2.21987173e-01, 1.97581983e+00, 2.29022694e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 2.22091556e+00, 2.57325020e+01,\n",
              "        1.54578257e+01, 0.00000000e+00, 3.39954019e+00, 1.77105832e+00,\n",
              "        6.54949963e-01, 4.66251820e-01, 1.93343234e+00, 2.47920442e+00,\n",
              "        3.99684811e+00, 8.33669758e+00, 5.65660334e+00, 3.14924073e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.06770295e-01,\n",
              "        3.20356637e-01, 0.00000000e+00, 2.30961094e+01, 8.08997345e+01,\n",
              "        7.73622208e+01, 5.20987282e+01, 4.42758369e+01, 2.95631886e+01,\n",
              "        8.56203938e+00, 6.34280816e-02, 1.90127623e+00, 1.00930691e+01,\n",
              "        4.62173882e+01, 8.80193100e+01, 5.83780479e+01, 2.43486958e+01],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.24726081e-01,\n",
              "        1.60661364e+00, 1.06823759e+01, 7.63932571e+01, 1.59208679e+02,\n",
              "        1.46317764e+02, 1.25753479e+02, 1.37945496e+02, 1.23475517e+02,\n",
              "        9.41749573e+01, 8.15956573e+01, 6.16204185e+01, 5.43355141e+01,\n",
              "        1.07070618e+02, 1.00811195e+02, 1.62315201e+02, 6.31157265e+01],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.02651834e-01,\n",
              "        4.50998640e+00, 8.14144897e+00, 1.15599350e+02, 2.15237061e+02,\n",
              "        1.94698196e+02, 1.71530579e+02, 1.17490067e+02, 1.56644501e+02,\n",
              "        1.44840729e+02, 1.20282768e+02, 1.21009521e+02, 1.39948135e+02,\n",
              "        1.33993225e+02, 1.53073151e+02, 2.13363281e+02, 6.40336914e+01],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.77691722e+00, 9.28699449e-02, 1.35112656e+02, 2.19893250e+02,\n",
              "        2.16780304e+02, 2.10589828e+02, 2.16344894e+02, 1.90958221e+02,\n",
              "        1.78166122e+02, 1.89050415e+02, 1.80222122e+02, 1.57126175e+02,\n",
              "        1.65211838e+02, 2.08949509e+02, 2.08938309e+02, 9.11837692e+01],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.77062386e-01,\n",
              "        2.21663788e-01, 3.74119720e+01, 1.58135925e+02, 2.21310318e+02,\n",
              "        2.27078339e+02, 2.27906006e+02, 2.26116623e+02, 2.25005859e+02,\n",
              "        2.22409683e+02, 2.20484131e+02, 2.20772736e+02, 2.21912186e+02,\n",
              "        2.21796249e+02, 2.28064377e+02, 2.30534943e+02, 1.52381180e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.52185038e-01, 6.59558892e-01,\n",
              "        5.77048898e-01, 7.09579620e+01, 2.10906906e+02, 2.28987640e+02,\n",
              "        2.24871826e+02, 2.26243500e+02, 2.29809036e+02, 2.23281036e+02,\n",
              "        2.19787796e+02, 2.14563126e+02, 2.12372879e+02, 2.15381409e+02,\n",
              "        2.19341507e+02, 2.22954697e+02, 2.05367783e+02, 2.03287292e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 2.45203450e-01, 8.74456584e-01, 6.45167530e-01,\n",
              "        3.35338563e-01, 3.10945225e+01, 1.89280945e+02, 2.24761398e+02,\n",
              "        2.17088318e+02, 2.15113281e+02, 1.98629623e+02, 1.78184128e+02,\n",
              "        2.17441605e+02, 2.09304535e+02, 2.16492081e+02, 2.23159317e+02,\n",
              "        2.15774200e+02, 2.33646515e+02, 1.54069000e+02, 1.56151642e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 5.77587448e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.76237823e+02, 2.22956818e+02,\n",
              "        2.16439133e+02, 2.16056488e+02, 1.97339508e+02, 1.78171616e+02,\n",
              "        2.13632339e+02, 2.15356598e+02, 2.13809906e+02, 2.19945389e+02,\n",
              "        2.21430481e+02, 2.25519867e+02, 2.02555237e+02, 1.42934570e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 5.69675192e-02, 7.60944724e-01,\n",
              "        4.21882957e-01, 6.46207619e+00, 1.52904694e+02, 2.21827194e+02,\n",
              "        2.17557281e+02, 2.17768402e+02, 2.08780319e+02, 2.05060333e+02,\n",
              "        2.14415192e+02, 2.16511368e+02, 2.19236237e+02, 2.27745102e+02,\n",
              "        2.25878723e+02, 2.16573441e+02, 2.26916473e+02, 1.94526581e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 5.33573687e-01, 2.37544847e+00,\n",
              "        2.23014569e+00, 3.63261604e+01, 1.62419952e+02, 2.34239471e+02,\n",
              "        2.24402527e+02, 2.25761246e+02, 2.29829147e+02, 2.35535568e+02,\n",
              "        2.24837570e+02, 2.17362030e+02, 2.17984329e+02, 2.24220306e+02,\n",
              "        2.24313797e+02, 2.15942322e+02, 2.25586884e+02, 2.35039124e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 2.50334572e-02, 2.05933595e+00,\n",
              "        2.26791573e+00, 1.69654808e+01, 9.77001572e+01, 2.32740616e+02,\n",
              "        2.24266357e+02, 2.25434814e+02, 2.22787018e+02, 2.18361679e+02,\n",
              "        2.18664200e+02, 2.19411530e+02, 2.22172012e+02, 2.23016510e+02,\n",
              "        2.25619629e+02, 2.30339661e+02, 2.30912231e+02, 2.37729568e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 3.98918092e-01, 2.88354492e+00,\n",
              "        0.00000000e+00, 3.67873335e+00, 2.19189606e+02, 2.23768356e+02,\n",
              "        2.15734192e+02, 2.21186600e+02, 2.18992264e+02, 2.10397430e+02,\n",
              "        2.14636108e+02, 2.24587112e+02, 1.97416870e+02, 1.86077621e+02,\n",
              "        2.31372894e+02, 2.33659393e+02, 2.24126358e+02, 2.28700348e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 2.89066225e-01, 1.93120861e+00,\n",
              "        1.20568216e+00, 1.50443956e-01, 0.00000000e+00, 1.02099352e+01,\n",
              "        5.51078072e+01, 1.25278381e+02, 2.17532990e+02, 2.13751190e+02,\n",
              "        2.09983185e+02, 2.09886093e+02, 2.10963867e+02, 2.22813812e+02,\n",
              "        2.30503983e+02, 2.42084961e+02, 2.26565323e+02, 2.25385529e+02,\n",
              "        2.23918167e+02, 2.12263733e+02, 2.14864807e+02, 2.24579346e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        4.51651841e-01, 2.63572526e+00, 5.37661648e+00, 5.03342152e+00,\n",
              "        1.83079755e+00, 1.92390472e-01, 0.00000000e+00, 6.75815582e+01,\n",
              "        1.55564102e+02, 2.05094131e+02, 2.18967377e+02, 2.17950287e+02,\n",
              "        2.09371399e+02, 2.12636612e+02, 2.00613632e+02, 2.12870850e+02,\n",
              "        2.28891052e+02, 2.18626617e+02, 1.90099396e+02, 1.98879501e+02,\n",
              "        2.09452652e+02, 2.10222214e+02, 2.18607376e+02, 2.23180054e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.52488267e-01,\n",
              "        9.53560054e-01, 6.17272794e-01, 2.39123087e-02, 6.91738510e+00,\n",
              "        2.80036240e+01, 6.35178833e+01, 1.28500107e+02, 2.04592987e+02,\n",
              "        2.20197998e+02, 2.13262360e+02, 2.08669693e+02, 1.88940781e+02,\n",
              "        1.56810455e+02, 2.02455490e+02, 2.36080460e+02, 2.27169083e+02,\n",
              "        1.97345078e+02, 1.79659760e+02, 1.98431320e+02, 2.17574356e+02,\n",
              "        2.14687653e+02, 2.14296097e+02, 2.22281708e+02, 2.20634293e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.98016667e-01,\n",
              "        9.65438604e-01, 0.00000000e+00, 5.05458736e+00, 6.41017380e+01,\n",
              "        1.25066574e+02, 1.74817841e+02, 1.97530411e+02, 2.05501785e+02,\n",
              "        2.10389236e+02, 2.07213058e+02, 2.18928925e+02, 2.31534592e+02,\n",
              "        1.22235237e+02, 1.08442360e+02, 1.22898010e+02, 1.10533760e+02,\n",
              "        1.38850739e+02, 1.93920120e+02, 2.20416504e+02, 2.19063110e+02,\n",
              "        2.10149368e+02, 1.99315796e+02, 1.93546448e+02, 1.87651703e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.03565073e+00,\n",
              "        3.47112312e+01, 1.34577469e+02, 1.96906876e+02, 2.23343552e+02,\n",
              "        2.17007706e+02, 2.15790665e+02, 2.13139908e+02, 2.09389572e+02,\n",
              "        2.10679825e+02, 2.00773178e+02, 2.13120544e+02, 2.16545792e+02,\n",
              "        2.29919785e+02, 1.65234482e+02, 1.65048767e+02, 2.08485077e+02,\n",
              "        2.36251053e+02, 2.27203644e+02, 2.13335175e+02, 1.98027252e+02,\n",
              "        1.83884537e+02, 1.80079651e+02, 1.69655182e+02, 1.65156433e+02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.82385445e-01,\n",
              "        1.09168236e+02, 2.06797516e+02, 2.22962906e+02, 2.21306870e+02,\n",
              "        2.18539032e+02, 2.21857529e+02, 2.29365753e+02, 2.42880859e+02,\n",
              "        2.19531036e+02, 1.97772491e+02, 2.03669968e+02, 2.01581802e+02,\n",
              "        2.09317200e+02, 2.24439468e+02, 2.24451065e+02, 2.28571747e+02,\n",
              "        2.17332993e+02, 2.03009689e+02, 1.96897705e+02, 1.94542145e+02,\n",
              "        1.96187866e+02, 1.87124542e+02, 1.79932465e+02, 1.84164291e+02],\n",
              "       [1.53885877e+00, 2.22672606e+00, 2.91459322e+00, 2.20779171e+01,\n",
              "        1.56231094e+02, 2.13499390e+02, 2.07491653e+02, 2.14635620e+02,\n",
              "        2.16723434e+02, 2.16968857e+02, 2.20565674e+02, 2.19764969e+02,\n",
              "        1.99865570e+02, 1.93032272e+02, 2.04958740e+02, 2.15204956e+02,\n",
              "        2.18035797e+02, 2.15028900e+02, 2.08099487e+02, 2.00410324e+02,\n",
              "        1.94481094e+02, 1.97514908e+02, 2.03048431e+02, 2.06285522e+02,\n",
              "        2.07740952e+02, 1.84822830e+02, 1.77845581e+02, 1.73609970e+02],\n",
              "       [4.91995697e+01, 7.09820328e+01, 9.27644958e+01, 9.39938965e+01,\n",
              "        1.45203873e+02, 2.11538177e+02, 2.08115067e+02, 2.00227783e+02,\n",
              "        2.00378082e+02, 1.99459122e+02, 1.92600647e+02, 1.91017273e+02,\n",
              "        1.96356995e+02, 2.01660889e+02, 2.09574631e+02, 2.08062271e+02,\n",
              "        2.07485062e+02, 2.01209396e+02, 1.95786118e+02, 1.97810867e+02,\n",
              "        2.03061554e+02, 1.99961853e+02, 1.95030899e+02, 1.88721115e+02,\n",
              "        1.81427017e+02, 1.38058594e+02, 9.25445251e+01, 5.41238098e+01],\n",
              "       [8.74275970e+01, 8.21539459e+01, 7.68803024e+01, 7.10165024e+01,\n",
              "        9.21337967e+01, 2.01867828e+02, 1.88902725e+02, 1.95905533e+02,\n",
              "        2.01773788e+02, 1.83430435e+02, 1.83901520e+02, 1.95972397e+02,\n",
              "        1.97763199e+02, 1.96969437e+02, 1.93992264e+02, 1.89717499e+02,\n",
              "        1.95933273e+02, 2.01126694e+02, 2.08584976e+02, 1.98203369e+02,\n",
              "        1.82756943e+02, 1.32050827e+02, 8.98458176e+01, 4.85359879e+01,\n",
              "        6.78054857e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [6.33082428e+01, 5.71174393e+01, 5.09266319e+01, 4.21970253e+01,\n",
              "        3.11911507e+01, 1.48021027e+02, 2.05710770e+02, 1.95168503e+02,\n",
              "        1.88393753e+02, 1.83328705e+02, 1.78794449e+02, 1.73575134e+02,\n",
              "        1.86116119e+02, 2.04945099e+02, 2.23031769e+02, 2.36707489e+02,\n",
              "        2.22652832e+02, 1.58080658e+02, 9.69273758e+01, 4.30784683e+01,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [2.84934540e+01, 1.74875774e+01, 6.48170090e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 3.88170662e+01, 8.06949539e+01, 1.47990082e+02,\n",
              "        1.64571869e+02, 1.74747864e+02, 2.03407806e+02, 2.26208435e+02,\n",
              "        2.08527267e+02, 1.67724426e+02, 1.28812454e+02, 8.69685593e+01,\n",
              "        3.56020355e+01, 1.48086548e+01, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.35224044e-01,\n",
              "        5.93802214e-01, 5.44881642e-01, 8.24381924e+00, 1.87851298e+00,\n",
              "        2.08689156e+01, 6.47611160e+01, 6.79865952e+01, 3.38778076e+01,\n",
              "        4.01472130e+01, 3.60837517e+01, 2.08340511e+01, 1.18157215e+01,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [7.06206262e-01, 1.16478443e+00, 1.62336266e+00, 1.91805923e+00,\n",
              "        1.45948100e+00, 7.47724652e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.64445710e-01,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zWEmZebAOyj",
        "colab_type": "text"
      },
      "source": [
        "##Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8EItRke_zii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f5a86c9a-3973-41ed-ec9e-23d8fb012407"
      },
      "source": [
        "model_pooling_conv.evaluate(x_test_conv,y_test_class)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 337us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31857962555885316, 0.8832]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBv-lz0IAUdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}